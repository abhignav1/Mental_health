---
title: "x"
output: html_document
date: "2025-07-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Set working directory
setwd("C:/Mental_health")

# Load required packages
library(tidyverse)
library(caret)
library(xgboost)
library(Matrix)

# Read the dataset
data <- read_csv("C:/Users/av1265/Downloads/digital_diet_mental_health.csv")

# Feature engineering
data <- data %>%
  mutate(
    screen_per_hour_awake = daily_screen_time_hours / (24 - sleep_duration_hours),
    stress_to_sleep_ratio = stress_level / (sleep_duration_hours + 1),
    screen_stress_ratio = daily_screen_time_hours / (stress_level + 1),
    caffeine_sleep_ratio = caffeine_intake_mg_per_day / (sleep_duration_hours + 1),
    digital_exhaustion = (daily_screen_time_hours + phone_usage_hours) * stress_level / (sleep_duration_hours + 1),
    wellbeing_score = mindfulness_minutes_per_day + physical_activity_hours_per_week - caffeine_intake_mg_per_day,
    burnout_score = mental_health_score
  ) %>%
  select(-user_id)

# Train-test split
set.seed(42)
train_index <- createDataPartition(data$burnout_score, p = 0.8, list = FALSE)
train <- data[train_index, ]
test <- data[-train_index, ]

# Split into features and target
train_y <- train$burnout_score
test_y <- test$burnout_score
train_x <- train %>% select(-burnout_score)
test_x <- test %>% select(-burnout_score)

# One-hot encoding
dummies_model <- dummyVars(" ~ .", data = train_x)
train_x_mat <- as.data.frame(predict(dummies_model, newdata = train_x))
test_x_mat <- as.data.frame(predict(dummies_model, newdata = test_x))

# Remove highly correlated and low variance predictors
cor_matrix <- cor(train_x_mat)
high_cor <- findCorrelation(cor_matrix, cutoff = 0.85)
if (length(high_cor) > 0) {
  keep_cols <- setdiff(colnames(train_x_mat), colnames(train_x_mat)[high_cor])
  train_x_mat <- train_x_mat[, keep_cols]
  test_x_mat <- test_x_mat[, keep_cols]
} else {
  keep_cols <- colnames(train_x_mat)
}
nzv <- nearZeroVar(train_x_mat)
if (length(nzv) > 0) {
  train_x_mat <- train_x_mat[, -nzv]
  test_x_mat <- test_x_mat[, -nzv]
}

# Convert to DMatrix
dtrain <- xgb.DMatrix(data = as.matrix(train_x_mat), label = train_y)
dtest <- xgb.DMatrix(data = as.matrix(test_x_mat), label = test_y)

# XGBoost parameters
params <- list(
  objective = "reg:squarederror",
  eval_metric = "rmse",
  eta = 0.05,
  max_depth = 5,
  subsample = 0.8,
  colsample_bytree = 0.9
)

# Cross-validation
cv <- xgb.cv(
  params = params,
  data = dtrain,
  nrounds = 300,
  nfold = 5,
  early_stopping_rounds = 20,
  verbose = 0
)

# Train final model
best_nrounds <- cv$best_iteration
model <- xgboost(
  data = dtrain,
  params = params,
  nrounds = best_nrounds,
  verbose = 0
)

# Predict and evaluate
pred_score <- predict(model, dtest)
pred_class <- ifelse(pred_score < 50, 1, 0)
true_class <- ifelse(test_y < 50, 1, 0)
conf_matrix <- confusionMatrix(factor(pred_class), factor(true_class))
print(conf_matrix)
cat("\nRMSE:", sqrt(mean((pred_score - test_y)^2)), "\n")

# Save model and preprocessing in one RDS
preprocessing <- list(
  dummies_model = dummies_model,
  keep_cols = keep_cols
)
xgb.save(model, "xgb_model.model")
saveRDS(preprocessing, "preprocessing.rds")
```

